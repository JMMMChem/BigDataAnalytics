{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_fakenews.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbQLKwEG59SK"
      },
      "source": [
        "\n",
        "Sarcasm Detection: BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USeIE7ud5z29"
      },
      "source": [
        "# We will use the official tokenization script created by the Google team\n",
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxOR8kkl53Pg",
        "outputId": "6e4f905c-13f8-4876-9939-92514aba9a71"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 7.7MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbeUKhCL55Gx"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow_hub as hub\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tokenization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfp4uSAX6JYk"
      },
      "source": [
        "def bert_encode(texts, tokenizer, max_len=160):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19VDMlm56Otn"
      },
      "source": [
        "def build_model(bert_layer, max_len=160):\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    out = Dense(1, activation='sigmoid')(clf_output)\n",
        "    \n",
        "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy',keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.TruePositives()])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEpbQ37j6T7k",
        "outputId": "3516abbd-d8e9-4f72-96bc-c22d04122d29"
      },
      "source": [
        "%%time\n",
        "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 22.9 s, sys: 4.54 s, total: 27.5 s\n",
            "Wall time: 34.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW6PUxRE6Vqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "789a9c18-c9f8-4898-a5fa-b00393b59bb7"
      },
      "source": [
        "# Load the Drive helper and mount \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQH-vBUB6Zwr"
      },
      "source": [
        "cod_train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/fake-news/train\")\n",
        "cod_train.rename(columns={'text': 'content'}, inplace=True)\n",
        "cod_train=cod_train.dropna()\n",
        "\n",
        "#test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/fake-news/test\")\n",
        "cod_train2, test= train_test_split(cod_train, random_state=0, test_size=0.2)\n",
        "train, val =  train_test_split(cod_train2, random_state = 0,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52PtnA_s6e7P"
      },
      "source": [
        "\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "7USE_uNzOeqa",
        "outputId": "d29765ee-672e-4148-dc13-335f61ea808e"
      },
      "source": [
        "train.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11904</th>\n",
              "      <td>11904</td>\n",
              "      <td>Il Regno Unito riprende l’addestramento degli ...</td>\n",
              "      <td>Rachele Marmetti</td>\n",
              "      <td>Il Regno Unito riprende l’addestramento degli ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1512</th>\n",
              "      <td>1512</td>\n",
              "      <td>Beyond Voting: the Limits of Electoral Politics</td>\n",
              "      <td>Ken Knabb</td>\n",
              "      <td>(4) Representative democracy \\n(5) Overt minor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10790</th>\n",
              "      <td>10790</td>\n",
              "      <td>Immunotherapy Offers Hope to a Cancer Patient,...</td>\n",
              "      <td>Matt Richtel</td>\n",
              "      <td>DENVER  —   A cancer patient nicknamed the Ste...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>122</td>\n",
              "      <td>“Chapo Trap House”: New Left-Wing Podcast is a...</td>\n",
              "      <td>Eric Striker</td>\n",
              "      <td>“Chapo Trap House”: New Left-Wing Podcast is a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8779</th>\n",
              "      <td>8779</td>\n",
              "      <td>Trump Budget Director Mulveney: We Are ‘Dead S...</td>\n",
              "      <td>Charlie Spiering</td>\n",
              "      <td>President Donald Trump’s budget director Mick ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ... label\n",
              "11904  11904  ...     1\n",
              "1512    1512  ...     1\n",
              "10790  10790  ...     0\n",
              "122      122  ...     1\n",
              "8779    8779  ...     0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU5RoRS36oJx"
      },
      "source": [
        "\n",
        "train_input = bert_encode(train.content.values, tokenizer, max_len = 160)\n",
        "test_input = bert_encode(test.content.values, tokenizer, max_len = 160)\n",
        "val_input = bert_encode(val.content.values, tokenizer, max_len = 160)\n",
        "\n",
        "train_labels = train.label.values\n",
        "test_labels = test.label.values\n",
        "val_labels = val.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbIIN_eJ6qmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8609a185-d22b-409f-b500-919f9a842029"
      },
      "source": [
        "model = build_model(bert_layer, max_len = 160)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem (Slici (None, 1024)         0           keras_layer[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            1025        tf.__operators__.getitem[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 335,142,914\n",
            "Trainable params: 335,142,913\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KvcZXv46tRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c1b3ccb-f7df-402b-af56-68df8145b7f7"
      },
      "source": [
        "# Save the model after every epoch.\n",
        "saveBestModel = ModelCheckpoint('best_model.hdf5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "# Stop training when a monitored quantity has stopped improving.\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWozltnx6vzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "087450ae-74a6-4862-e05a-0dac3b7dee7f"
      },
      "source": [
        "rain_history = model.fit(\n",
        "    train_input, train_labels,\n",
        "    validation_data=(val_input, val_labels),\n",
        "    epochs=8,\n",
        "    batch_size=10,\n",
        "    callbacks=[saveBestModel, earlyStopping]\n",
        ")\n",
        "\n",
        "#model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "1171/1171 [==============================] - 1506s 1s/step - loss: 0.2326 - accuracy: 0.8937 - precision: 0.8907 - recall: 0.8613 - true_positives: 2291.3422 - val_loss: 0.0478 - val_accuracy: 0.9826 - val_precision: 0.9822 - val_recall: 0.9767 - val_true_positives: 1216.0000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/8\n",
            "1171/1171 [==============================] - 1485s 1s/step - loss: 0.0250 - accuracy: 0.9930 - precision: 0.9925 - recall: 0.9913 - true_positives: 2536.6280 - val_loss: 0.0422 - val_accuracy: 0.9839 - val_precision: 0.9934 - val_recall: 0.9687 - val_true_positives: 1206.0000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/8\n",
            "1171/1171 [==============================] - 1485s 1s/step - loss: 0.0043 - accuracy: 0.9990 - precision: 0.9991 - recall: 0.9985 - true_positives: 2539.4616 - val_loss: 0.0461 - val_accuracy: 0.9870 - val_precision: 0.9919 - val_recall: 0.9775 - val_true_positives: 1217.0000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/8\n",
            "1171/1171 [==============================] - 1486s 1s/step - loss: 6.9711e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - true_positives: 2535.0384 - val_loss: 0.0495 - val_accuracy: 0.9870 - val_precision: 0.9910 - val_recall: 0.9783 - val_true_positives: 1218.0000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/8\n",
            "1171/1171 [==============================] - 1487s 1s/step - loss: 1.6203e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - true_positives: 2543.1041 - val_loss: 0.0544 - val_accuracy: 0.9874 - val_precision: 0.9911 - val_recall: 0.9791 - val_true_positives: 1219.0000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri4dvjoc6yCU"
      },
      "source": [
        "test_pred = model.predict(test_input)\n",
        "test_pred = test_pred.round().astype(int)\n",
        "\n",
        "#test_pred = model.predict_classes(test_input, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0ejFqnh61Fz"
      },
      "source": [
        "recall = metrics.recall_score(test_labels,test_pred)\n",
        "precision = metrics.precision_score(test_labels,test_pred)\n",
        "f1_score = metrics.f1_score(test_labels,test_pred)\n",
        "accuracy = metrics.accuracy_score(test_labels,test_pred)\n",
        "loss = metrics.log_loss(test_labels,test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxyWeLA463YD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556c1a5d-9b9e-4512-ed0b-f123477ddb38"
      },
      "source": [
        "print('Loss:',loss)\n",
        "print('Accuracy:',accuracy)\n",
        "print('Precision:',precision)\n",
        "print('Recall:',recall)\n",
        "print('f1 score:',f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.4250102622134122\n",
            "Accuracy: 0.9876948318293683\n",
            "Precision: 0.9863861386138614\n",
            "Recall: 0.9857761286332715\n",
            "f1 score: 0.9860810392824003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRwLzste68RS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0559e7d-18a4-40e6-8910-ce4cf902abe3"
      },
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# kappa\n",
        "kappa = cohen_kappa_score(test_labels,test_pred)\n",
        "print('Cohens kappa: %f' % kappa)\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(test_labels,test_pred)\n",
        "print('ROC AUC: %f' % auc)\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(test_labels,test_pred)\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cohens kappa: 0.975054\n",
            "ROC AUC: 0.987496\n",
            "[[2018   22]\n",
            " [  23 1594]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap7oCWuFv9W8"
      },
      "source": [
        "def getFP_FN_lists(test_X, test_y, pred_y):\n",
        "    FP_text = []\n",
        "    FP_index = []\n",
        "    FN_text = []\n",
        "    FN_index = []\n",
        "    for i in range(len(test_y)):\n",
        "        if(pred_y[i]==1 and test_y[test_y.index[i]]==0):\n",
        "            FP_text.append(test['content'][test_y.index[i]])\n",
        "            FP_index.append(test_y.index[i])\n",
        "        elif(pred_y[i]==0 and test_y[test_y.index[i]]==1):\n",
        "            FN_text.append(test['content'][test_y.index[i]])\n",
        "            FN_index.append(test_y.index[i]) \n",
        "            \n",
        "    return FP_text,FP_index,FN_text,FN_index\n",
        "\n",
        "\n",
        "def getFP_FN(test_X, test_y, pred_y):\n",
        "    FP_text,FP_index,FN_text,FN_index= getFP_FN_lists(test_X, test_y, pred_y)\n",
        "    d_FP = {'FP_text':FP_text,'FP_index':FP_index}\n",
        "    df_FP = pd.DataFrame(d_FP)\n",
        "    d_FN = {'FN_text':FN_text,'FN_index':FN_index}\n",
        "    df_FN = pd.DataFrame(d_FN)\n",
        "    \n",
        "    return df_FP,df_FN\n",
        "\n",
        "\n",
        "#df_FP,df_FN, df_TP = getFP_FN_TP(test_input, test_labels, test_pred)\n",
        "df_FP,df_FN = getFP_FN(test['content'], test['label'],test_pred)\n",
        "df_FP.to_csv('FP_BERT.csv', index=True)\n",
        "df_FN.to_csv('FN_BERT.csv', index=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgJrR-BL5paP"
      },
      "source": [
        "def getTPTN_lists(test_X, test_y, pred_y):\n",
        "    TP_text = []\n",
        "    TP_index = []\n",
        "    TN_text = []\n",
        "    TN_index = []\n",
        "    for i in range(len(test_y)):\n",
        "        if(pred_y[i]==1 and test_y[test_y.index[i]]==1):\n",
        "            TP_text.append(test['content'][test_y.index[i]])\n",
        "            TP_index.append(test_y.index[i])\n",
        "        elif(pred_y[i]==0 and test_y[test_y.index[i]]==0):\n",
        "            TN_text.append(test['content'][test_y.index[i]])\n",
        "            TN_index.append(test_y.index[i])\n",
        "\n",
        "    return TP_text,TP_index,TN_text,TN_index\n",
        "\n",
        "def getTPTN(test_X, test_y, pred_y):\n",
        "    TP_text,TP_index,TN_text,TN_index= getTPTN_lists(test_X, test_y, pred_y)\n",
        "    d_TP =  {'TP_text':TP_text,'TP_index':TP_index}\n",
        "    df_TP = pd.DataFrame(d_TP)\n",
        "    d_TN =  {'TN_text':TN_text,'TN_index':TN_index}\n",
        "    df_TN = pd.DataFrame(d_TN)\n",
        "\n",
        "    return df_TP,df_TN\n",
        "\n",
        " \n",
        "df_TP,df_TN = getTPTN(test['content'], test['label'],test_pred)\n",
        "df_TP.to_csv('TP_BERT.csv', index=True)\n",
        "df_TN.to_csv('TN_BERT.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
