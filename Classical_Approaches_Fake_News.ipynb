{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classical Approaches Fake News.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlwEdOq20MJr"
      },
      "source": [
        "Load the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9SUAiHUw3Lu",
        "outputId": "c05b2645-7b41-4927-b66e-fbf23b3e07ac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btNL-Yio5Dtq",
        "outputId": "4f1cda6a-f455-4eb6-cac2-f136286dd7ca"
      },
      "source": [
        "!pip install --user -U nltk\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: nltk in /root/.local/lib/python3.7/site-packages (3.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2019.12.20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBHJUk_GyTog",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "13700768-04c7-4975-da87-0e9e718a69e0"
      },
      "source": [
        "import pandas\n",
        "import csv\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd\n",
        "\n",
        "sst_home='drive/MyDrive/Colab Notebooks/'\n",
        "#modify this path \n",
        "path=sst_home+'fake-news/train'\n",
        "\n",
        "news = pd.read_csv(path)\n",
        "#news = pandas.read_csv(path, sep=',', quoting=csv.QUOTE_NONE, names=[\"label\", \"text\"])\n",
        "#shows the first messages\n",
        "news.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "0   0  ...     1\n",
              "1   1  ...     0\n",
              "2   2  ...     1\n",
              "3   3  ...     1\n",
              "4   4  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKEDAwq90FvB"
      },
      "source": [
        "Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XmYBkFpyr9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e87c1213-1466-486a-bb7e-301a83c64f99"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stopwords_en = stopwords.words(\"english\")\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "\n",
        "\n",
        "def cleanText(text):\n",
        "    text=str(text).lower()\n",
        "    \n",
        "    #tokeniza the text\n",
        "    tokens=word_tokenize(text)\n",
        "\n",
        "\n",
        "    \n",
        "    #remove the stopwords\n",
        "    tokens = [word for word in tokens if word not in stopwords_en]\n",
        "\n",
        "    \n",
        "    \n",
        "    #(4) obtain the stems\n",
        "    tokens = [PorterStemmer().stem(word) for word in tokens]\n",
        "\n",
        "    \n",
        "    #(5) finally, remove words with len <3 and words that contain numbers, puntuaction, ect\n",
        "    min_length = 3\n",
        "    p = re.compile('[a-zA-Z]+');\n",
        "    filtered_tokens=[]\n",
        "    for token in tokens:\n",
        "        if len(token)>=min_length and p.match(token):\n",
        "            filtered_tokens.append(token)\n",
        "            \n",
        "    return filtered_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5x4OMZN0HI3"
      },
      "source": [
        "Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "UO6ZUjLf2OPM",
        "outputId": "eadbb918-87d7-4892-93ff-62f2b2c97736"
      },
      "source": [
        "x= news.drop('label',axis=1)\n",
        "x.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                               text\n",
              "0   0  ...  House Dem Aide: We Didn’t Even See Comey’s Let...\n",
              "1   1  ...  Ever get the feeling your life circles the rou...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRVxyE5V2RyJ"
      },
      "source": [
        "y = news['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFGv-Pgs2aKb",
        "outputId": "cb37a469-7b3b-4842-840c-f20e588119e6"
      },
      "source": [
        "news.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id           0\n",
              "title      558\n",
              "author    1957\n",
              "text        39\n",
              "label        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "v0XhEJZ_2cUM",
        "outputId": "1d5531c2-4e1d-41ff-dbb7-5e55304012a8"
      },
      "source": [
        "news=news.dropna()\n",
        "\n",
        "messeges =news.copy()\n",
        "messeges.reset_index(inplace=True)\n",
        "messeges.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  id  ...                                               text label\n",
              "0      0   0  ...  House Dem Aide: We Didn’t Even See Comey’s Let...     1\n",
              "1      1   1  ...  Ever get the feeling your life circles the rou...     0\n",
              "2      2   2  ...  Why the Truth Might Get You Fired October 29, ...     1\n",
              "3      3   3  ...  Videos 15 Civilians Killed In Single US Airstr...     1\n",
              "4      4   4  ...  Print \\nAn Iranian woman has been sentenced to...     1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU6ODcwP5CDZ"
      },
      "source": [
        "y=messeges['label']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1AEhSsM2lCa",
        "outputId": "36ebd86b-3d16-4ed3-e9c5-ed8d8ae0626c"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "nltk.download('stopwords')\n",
        "corpus = []\n",
        "for i in range(0, len(messeges)):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', messeges['title'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39d9-r_O40XR"
      },
      "source": [
        "cv = CountVectorizer(max_features=5000,ngram_range=(1,3))\n",
        "X = cv.fit_transform(corpus).toarray()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLXKrtPAz3cM"
      },
      "source": [
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "#bow = CountVectorizer(analyzer=cleanText).fit(news['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HW7BkxX0D68"
      },
      "source": [
        "#matrix_bow = bow.transform(news['text'])\n",
        "#print('sparse matrix shape:', matrix_bow.shape)\n",
        "#print('total elements:',matrix_bow.shape[0] * matrix_bow.shape[1])\n",
        "#print( 'number of non-zeros:', matrix_bow.nnz)\n",
        "#print( 'sparsity: %.2f%%' % (100.0 * matrix_bow.nnz / (matrix_bow.shape[0] * matrix_bow.shape[1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPJAn9qF0c_R"
      },
      "source": [
        "TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku63egSv77nC",
        "outputId": "2988cd8e-3ffd-4c98-f923-21f0c80eefff"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "path2=sst_home+'fake-news/test'\n",
        "\n",
        "train = news\n",
        "test=pd.read_csv(path2)\n",
        "\n",
        "test=test.fillna(' ')\n",
        "train=train.fillna(' ')\n",
        "test['total']=test['title']+' '+test['author']+test['text']\n",
        "train['total']=train['title']+' '+train['author']+train['text']\n",
        "\n",
        "#tfidf\n",
        "transformer = TfidfTransformer(smooth_idf=False)\n",
        "count_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "counts = count_vectorizer.fit_transform(train['total'].values)\n",
        "tfidf = transformer.fit_transform(counts)\n",
        "targets = train['label'].values\n",
        "test_counts = count_vectorizer.transform(test['total'].values)\n",
        "test_tfidf = transformer.fit_transform(test_counts)\n",
        "\n",
        "#split in samples\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf, targets, random_state=0, test_size=0.2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state =0, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:1466: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  idf = np.log(n_samples / df) + 1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4fslMo_0f1q"
      },
      "source": [
        " #ANTIGUO\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "#first, we train the transformer to tf-idf model\n",
        "tfidf_transformer = TfidfTransformer().fit(matrix_bow)\n",
        "\n",
        "#now, we transform the bow matrix to a new matrix based on tf-idf\n",
        "tfidf_vectors = tfidf_transformer.transform(matrix_bow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IstFwnJfhXA4"
      },
      "source": [
        "Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBZeSKrbhWYg"
      },
      "source": [
        "#ANTIGUO\n",
        "\n",
        "bow = CountVectorizer(analyzer=cleanText).fit(msg_train)\n",
        "#transform the training set to bow model\n",
        "bow_train = bow.transform(msg_train)\n",
        "#transform the test set to bow model\n",
        "bow_test=bow.transform(msg_test)\n",
        "\n",
        "\n",
        "#learn the tf-idf model from the training bow\n",
        "tfidf_transformer = TfidfTransformer().fit(bow_train)\n",
        "#transform the training set to tf-idf model\n",
        "tfidf_train = tfidf_transformer.transform(bow_train)\n",
        "#transform the test set to tf-idf model\n",
        "tfidf_test = tfidf_transformer.transform(bow_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3bHgEfZ0ubX"
      },
      "source": [
        "Training and testing with a pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN7O47xm0s2y"
      },
      "source": [
        "#ANTIGUO\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, train_test_split \n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#news_train, news_test, label_train, label_test = train_test_split(news['text'], news['label'], test_size=0.2)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer(analyzer=cleanText)),  # strings to token integer counts\n",
        "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
        "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
        "])\n",
        "\n",
        "pipeline.fit(news_train,label_train)\n",
        "predictions = pipeline.predict(news_test)\n",
        "\n",
        "print( classification_report(label_test, predictions))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YksUi75Zysr2"
      },
      "source": [
        "Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95IMW0VD9_YM",
        "outputId": "9c17f1d1-4eb7-4879-9eeb-5d48ad3f5c9d"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier=MultinomialNB()\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import itertools\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "classifier.fit(X_train, y_train)\n",
        "pred = classifier.predict(X_test)\n",
        "score = metrics.accuracy_score(y_test, pred)\n",
        "print(\"accuracy:   %0.3f\" % score)\n",
        "#cm = metrics.confusion_matrix(y_test, pred)\n",
        "print( classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:   0.648\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      1.00      0.76      2040\n",
            "           1       1.00      0.20      0.34      1617\n",
            "\n",
            "    accuracy                           0.65      3657\n",
            "   macro avg       0.81      0.60      0.55      3657\n",
            "weighted avg       0.78      0.65      0.57      3657\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9nYZIzcygBh"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import graphviz\n",
        "import scipy.stats as stats\n",
        "#import optuna\n",
        "import plotly\n",
        "import math\n",
        "from sklearn import tree, neighbors\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "#from skopt import BayesSearchCV\n",
        "#from skopt.space import Integer, Real, Categorical\n",
        "from scipy.stats import uniform, expon\n",
        "from scipy.stats import randint as sp_randint\n",
        "from numpy.random import randint\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn import ensemble\n",
        "import xgboost as xgb\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, chi2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gZvlwO6yhVG"
      },
      "source": [
        "**SVM**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwRuInRg7116"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "clf = svm.SVC()\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "label_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuFSvVrJ8sio",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fbb0ac6-26d1-44ca-9ca1-f8e661f31e60"
      },
      "source": [
        "print(confusion_matrix(y_test,label_pred))\n",
        "print(classification_report(y_test,label_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2001   39]\n",
            " [  92 1525]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      2040\n",
            "           1       0.98      0.94      0.96      1617\n",
            "\n",
            "    accuracy                           0.96      3657\n",
            "   macro avg       0.97      0.96      0.96      3657\n",
            "weighted avg       0.96      0.96      0.96      3657\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz3Fny4ayj3J"
      },
      "source": [
        "**Logistic** **regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmlLYWimylr_"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', random_state=0).fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsX5Hp6G7uQJ"
      },
      "source": [
        "And evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsRbeDuo7lhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d1586b-c302-4a61-bf3c-748af1cd64fa"
      },
      "source": [
        "model.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.58796507, 0.41203493],\n",
              "       [0.69933089, 0.30066911],\n",
              "       [0.02970106, 0.97029894],\n",
              "       ...,\n",
              "       [0.86746812, 0.13253188],\n",
              "       [0.76584172, 0.23415828],\n",
              "       [0.52702747, 0.47297253]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBfyAZm77llY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a469ea8-4adf-4d93-e80f-114e8295c87a"
      },
      "source": [
        "model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYQUW_Wl7lrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b0c1a6-e4c1-4a73-8db2-311cccee9336"
      },
      "source": [
        "model.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9472245009570687"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9v9djjR7l1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "418d6cc3-b1db-45a8-bec5-196883b60811"
      },
      "source": [
        "confusion_matrix(y_test, model.predict(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1977,   63],\n",
              "       [ 130, 1487]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0tUSvuA7l6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670458bd-8b57-493f-b8aa-ec47fa741b14"
      },
      "source": [
        "print(classification_report(y_test, model.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95      2040\n",
            "           1       0.96      0.92      0.94      1617\n",
            "\n",
            "    accuracy                           0.95      3657\n",
            "   macro avg       0.95      0.94      0.95      3657\n",
            "weighted avg       0.95      0.95      0.95      3657\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73E3T6dVyl8A"
      },
      "source": [
        "**KNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqqPs1wxyvku"
      },
      "source": [
        "#Convert categorical labels to binary ones\n",
        "\n",
        "#import pandas as pd\n",
        "#binary_test = pd.get_dummies(label_test)\n",
        "#binary_test = binary_test.drop([\"ham\"], axis=1) \n",
        "\n",
        "#binary_train = pd.get_dummies(label_train)\n",
        "#binary_train = binary_train.drop([\"ham\"], axis=1) \n",
        "\n",
        "np.random.seed(0)\n",
        "neigh = KNeighborsClassifier()\n",
        "start = time.time()\n",
        "neigh = neigh.fit(X_train,y_train)\n",
        "end = time.time()\n",
        "totaltime_knn = end-start\n",
        "label_train_pred = neigh.predict(X_train)\n",
        "label_test_pred = neigh.predict(X_test)\n",
        "\n",
        "final_model_tree = neigh.fit(X_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVd4eiPKbFxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb92ab83-792a-4c03-9ed0-83330df423a2"
      },
      "source": [
        "print(classification_report(y_test, neigh.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.62      0.73      2040\n",
            "           1       0.65      0.90      0.75      1617\n",
            "\n",
            "    accuracy                           0.74      3657\n",
            "   macro avg       0.77      0.76      0.74      3657\n",
            "weighted avg       0.78      0.74      0.74      3657\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uUU6k04zE9H"
      },
      "source": [
        "**Random** **Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMJWzuBYzL2f"
      },
      "source": [
        "np.random.seed(0)\n",
        "rf = RandomForestClassifier()\n",
        "rf = rf.fit(X_train,y_train)\n",
        "label_test_pred2 = rf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwgT72eNbRMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a1237e5-3af0-4b8f-8e8e-0468318eac3e"
      },
      "source": [
        "print(classification_report(y_test, rf.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.91      2040\n",
            "           1       0.97      0.79      0.87      1617\n",
            "\n",
            "    accuracy                           0.90      3657\n",
            "   macro avg       0.91      0.89      0.89      3657\n",
            "weighted avg       0.91      0.90      0.90      3657\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38DEJe2xzSxR"
      },
      "source": [
        "**Gradient** **Boosting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-t7j_npzU9B"
      },
      "source": [
        " np.random.seed(0)\n",
        "gf = xgb.XGBClassifier()\n",
        "gf = gf.fit(X_train,y_train)\n",
        "label_test_pred3 = gf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoytUNIBbDdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0f64396-992c-4b8d-f2f7-455b57c50012"
      },
      "source": [
        "print(classification_report(y_test, gf.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97      2040\n",
            "           1       0.96      0.97      0.97      1617\n",
            "\n",
            "    accuracy                           0.97      3657\n",
            "   macro avg       0.97      0.97      0.97      3657\n",
            "weighted avg       0.97      0.97      0.97      3657\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}